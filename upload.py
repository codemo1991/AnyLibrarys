import streamlit as st
from fastapi import FastAPI, HTTPException, UploadFile, File
from pymilvus import Collection, CollectionSchema, FieldSchema, DataType, Index, connections, utility
from sentence_transformers import SentenceTransformer
import numpy as np
from elasticsearch import Elasticsearch
from minio import Minio
from tika import parser
import os
import tempfile
import hashlib
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# âœ… **åˆå§‹åŒ– MinIO**
MINIO_SERVER = os.getenv("MINIO_SERVER")
MINIO_ACCESS_KEY = os.getenv("MINIO_ACCESS_KEY")
MINIO_SECRET_KEY = os.getenv("MINIO_SECRET_KEY")
BUCKET_NAME = os.getenv("BUCKET_NAME")

minio_client = Minio(
    MINIO_SERVER,
    access_key=MINIO_ACCESS_KEY,
    secret_key=MINIO_SECRET_KEY,
    secure=False
)
if not minio_client.bucket_exists(BUCKET_NAME):
    minio_client.make_bucket(BUCKET_NAME)

# âœ… **åˆå§‹åŒ– Elasticsearch**
ES_HOST = os.getenv("ES_HOST")
es = Elasticsearch(ES_HOST)
INDEX_NAME = os.getenv("ES_INDEX_NAME")

# åˆ›å»ºç´¢å¼•æ˜ å°„
index_mapping = {
    "mappings": {
        "properties": {
            "filename": {"type": "text"},
            "content": {"type": "text"},
            "file_url": {"type": "text"},
            "milvus_id": {"type": "long"},
            "file_md5": {"type": "keyword"}  # æ·»åŠ md5å­—æ®µ
        }
    }
}

# æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨,ä¸å­˜åœ¨åˆ™åˆ›å»º
if not es.indices.exists(index=INDEX_NAME):
    es.indices.create(index=INDEX_NAME, body=index_mapping)

# âœ… **è¿æ¥ Milvus**
connections.connect(
    host=os.getenv("MILVUS_HOST"),
    port=os.getenv("MILVUS_PORT")
)

# âœ… **åˆ›å»º Collection**
collection_name = os.getenv("MILVUS_COLLECTION")
VECTOR_DIM = int(os.getenv("VECTOR_DIM"))

fields = [
    FieldSchema(name="id", dtype=DataType.INT64,
                is_primary=True, auto_id=True),
    FieldSchema(name="vector", dtype=DataType.FLOAT_VECTOR, dim=VECTOR_DIM)
]

schema = CollectionSchema(fields, description="Document embeddings for search")

# **æ£€æŸ¥ Collection æ˜¯å¦å­˜åœ¨**
if utility.has_collection(collection_name):
    collection = Collection(name=collection_name)
    print(f"âœ… Collection '{collection_name}' already exists.")
else:
    collection = Collection(name=collection_name, schema=schema)
    print(f"âœ… Collection '{collection_name}' created.")

# âœ… **åˆ›å»ºç´¢å¼•**
index_params = {
    "index_type": "IVF_FLAT",
    "metric_type": "L2",
    "params": {"nlist": 1024}
}
collection.create_index(field_name="vector", index_params=index_params)

# âœ… **åŠ è½½ Collection**
collection.load()

# âœ… **åˆå§‹åŒ–æ–‡æœ¬åµŒå…¥æ¨¡å‹**
model = SentenceTransformer(os.getenv("MODEL_NAME"))


# âœ… **Streamlit UI**
st.title("ğŸ“„ æ–‡æ¡£ç®¡ç† & è¯­ä¹‰æœç´¢")

# âœ… **ä¸Šä¼ æ–‡ä»¶éƒ¨åˆ†**
st.header("ğŸ“¤ æ–‡æ¡£ä¸Šä¼ ")
uploaded_file = st.file_uploader("é€‰æ‹©æ–‡ä»¶", type=['txt', 'pdf', 'doc', 'docx'])

if uploaded_file is not None:
    if st.button("ä¸Šä¼ æ–‡ä»¶"):
        with st.spinner('ğŸ”„ æ­£åœ¨ä¸Šä¼ æ–‡ä»¶...'):
            temp_path = None
            try:
                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmp_file:
                    file_content = uploaded_file.getbuffer()
                    tmp_file.write(file_content)
                    temp_path = tmp_file.name
                    
                    # è®¡ç®—æ–‡ä»¶MD5
                    file_md5 = hashlib.md5(file_content).hexdigest()

                    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨åŒåä¸”MD5ç›¸åŒçš„æ–‡ä»¶
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
                    es_result = es.search(index=INDEX_NAME, query={
                        "bool": {
                            "must": [
                                {"match": {"filename": uploaded_file.name}},
                                {"match": {"file_md5": file_md5}}
                            ]
                        }
                    })
                    
                    
                    if es_result["hits"]["total"]["value"] > 0:
                        st.success("âœ… æ–‡ä»¶å·²å­˜åœ¨ï¼Œæ— éœ€é‡å¤ä¸Šä¼ !")
                    else:
                        # âœ… **å­˜å…¥ MinIO**
                        minio_client.fput_object(
                            BUCKET_NAME, uploaded_file.name, temp_path)
                        file_url = f"http://{MINIO_SERVER}/{BUCKET_NAME}/{uploaded_file.name}"

                        # âœ… **æå–æ–‡æœ¬**
                        text = parser.from_file(temp_path).get("content", "").strip()
                        if not text:
                            st.error("âŒ æ— æ³•æå–æ–‡ä»¶å†…å®¹")
                        else:
                            # âœ… **ç”Ÿæˆå‘é‡**
                            vector = model.encode(text).tolist()

                            # âœ… **å­˜å…¥ Milvus**
                            insert_result = collection.insert([[vector]])
                            milvus_id = insert_result.primary_keys[0]  # è·å–æ’å…¥çš„ID

                            # âœ… **å­˜å…¥ Elasticsearch**
                            document = {
                                "filename": uploaded_file.name,
                                "content": text,
                                "file_url": file_url,
                                "milvus_id": milvus_id,
                                "file_md5": file_md5
                            }
                            es.index(index=INDEX_NAME, document=document)

                            st.success("âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ!")

            except Exception as e:
                st.error(f"âš  å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            finally:
                # ç¡®ä¿ä¸´æ—¶æ–‡ä»¶å­˜åœ¨ä¸”æ²¡æœ‰è¢«å…¶ä»–è¿›ç¨‹ä½¿ç”¨æ—¶å†åˆ é™¤
                if temp_path and os.path.exists(temp_path):
                    try:
                        os.unlink(temp_path)
                    except PermissionError:
                        # å¦‚æœæ–‡ä»¶æ­£åœ¨è¢«ä½¿ç”¨ï¼Œè®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­ç¨‹åº
                        print(f"Warning: Could not delete temporary file {temp_path}")


# âœ… **æœç´¢éƒ¨åˆ†**
st.header("ğŸ” æ–‡æ¡£æœç´¢")
search_query = st.text_input("è¾“å…¥æœç´¢å…³é”®è¯")

if st.button("ğŸ” æœç´¢") and search_query:
    with st.spinner('â³ æ­£åœ¨æœç´¢...'):
        try:
            # âœ… **Elasticsearch æœç´¢**
            es_query = {
                "query": {
                    "match": {"content": search_query}
                },
                "_source": ["filename", "file_url", "content", "file_md5"],
                "size": 10,
                "highlight": {
                    "fields": {
                        "content": {
                            "fragment_size": 100,  # å‡å°ä¸º100å­—ç¬¦
                            "number_of_fragments": 1,
                            "pre_tags": [""],
                            "post_tags": [""]
                        }
                    }
                }
            }
            es_results = es.search(index=INDEX_NAME, body=es_query)

            # âœ… **Milvus å‘é‡æœç´¢**
            query_vector = model.encode(search_query).tolist()
            search_results = collection.search(
                data=[query_vector], 
                anns_field="vector", 
                param={"metric_type": "L2", "params": {"nprobe": 10}},
                limit=5,
                output_fields=["id"]
            )
            milvus_ids = [result.entity.get("id") for result in search_results[0]]

            # âœ… **æ˜¾ç¤ºæœç´¢ç»“æœ**
            st.subheader("ğŸ“Œ æœç´¢ç»“æœ")

            # **Elasticsearch ç»“æœ**
            st.write("ğŸ“„ æ–‡æœ¬åŒ¹é…ç»“æœ:")
            for hit in es_results["hits"]["hits"]:
                st.write(f"ğŸ“‚ æ–‡ä»¶å: {hit['_source']['filename']}")
                st.write(f"ğŸ”— æ–‡ä»¶é“¾æ¥: {hit['_source']['file_url']}")
                # å®‰å…¨è·å–file_md5å­—æ®µ
                file_md5 = hit['_source'].get('file_md5', 'æœªçŸ¥')
                st.write(f"ğŸ“ æ–‡ä»¶MD5: {file_md5}")
                
                # è·å–åŒ¹é…å†…å®¹çš„ä¸Šä¸‹æ–‡
                content = hit['_source']['content']
                highlight = hit.get('highlight', {}).get('content', [''])[0]
                
                if highlight:
                    start_pos = content.find(highlight)
                    if start_pos != -1:
                        context_start = max(0, start_pos - 50)  # å‡å°ä¸º50å­—ç¬¦
                        context_end = min(len(content), start_pos + len(highlight) + 50)  # å‡å°ä¸º50å­—ç¬¦
                        context = content[context_start:context_end]
                        
                        if context_start > 0:
                            context = "..." + context
                        if context_end < len(content):
                            context = context + "..."
                            
                        st.write("ğŸ“ ç›¸å…³å†…å®¹:")
                        st.text(context)
                
                st.write("---")

            # **Milvus ç»“æœ**
            st.write("ğŸ” å‘é‡ç›¸ä¼¼åº¦ç»“æœ:")
            for milvus_id in milvus_ids:
                # é€šè¿‡ESæŸ¥è¯¢è·å–å¯¹åº”æ–‡æ¡£å†…å®¹
                es_query = {
                    "query": {
                        "term": {
                            "milvus_id": milvus_id
                        }
                    },
                    "_source": ["filename", "content", "file_md5"]
                }
                es_result = es.search(index=INDEX_NAME, body=es_query)
                if es_result["hits"]["hits"]:
                    doc = es_result["hits"]["hits"][0]["_source"]
                    content = doc["content"]
                    filename = doc["filename"]
                    # å®‰å…¨è·å–file_md5å­—æ®µ
                    file_md5 = doc.get('file_md5', 'æœªçŸ¥')
                    
                    # æ‰¾åˆ°æœ€ç›¸å…³çš„æ®µè½ï¼ˆè¿™é‡Œç®€å•åœ°å–ä¸­é—´éƒ¨åˆ†ä½œä¸ºç¤ºä¾‹ï¼‰
                    content_len = len(content)
                    if content_len > 100:  # å¦‚æœå†…å®¹è¶…è¿‡100å­—ç¬¦
                        start = max(0, content_len//2 - 50)
                        end = min(content_len, content_len//2 + 50)
                        context = "..." + content[start:end] + "..."
                    else:
                        context = content
                        
                    st.write(f"ğŸ“‚ æ–‡ä»¶å: {filename}")
                    st.write(f"ğŸ“ æ–‡ä»¶MD5: {file_md5}")
                    st.write("ğŸ“ ç›¸å…³å†…å®¹:")
                    st.text(context)
                    st.write("---")

        except Exception as e:
            st.error(f"âš  æœç´¢æ—¶å‡ºé”™: {str(e)}")
